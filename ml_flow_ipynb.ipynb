{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-2.19.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting mlflow-skinny==2.19.0 (from mlflow)\n",
      "  Downloading mlflow_skinny-2.19.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow) (3.1.4)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting markdown<4,>=3.3 (from mlflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow) (2.1.3)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow) (18.1.0)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow) (1.6.0)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow) (1.14.1)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Downloading SQLAlchemy-2.0.36-cp313-cp313-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting waitress<4 (from mlflow)\n",
      "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow-skinny==2.19.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow-skinny==2.19.0->mlflow) (8.1.7)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading databricks_sdk-0.40.0-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow-skinny==2.19.0->mlflow) (3.1.43)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<25 in c:\\users\\krebi\\appdata\\roaming\\python\\python313\\site-packages (from mlflow-skinny==2.19.0->mlflow) (24.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow-skinny==2.19.0->mlflow) (5.29.0)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow-skinny==2.19.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mlflow-skinny==2.19.0->mlflow) (2.32.3)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\krebi\\appdata\\roaming\\python\\python313\\site-packages (from docker<8,>=4.0.0->mlflow) (308)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Collecting Werkzeug>=3.1 (from Flask<4->mlflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting itsdangerous>=2.2 (from Flask<4->mlflow)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\krebi\\appdata\\roaming\\python\\python313\\site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<4->mlflow) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<4->mlflow) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\krebi\\appdata\\roaming\\python\\python313\\site-packages (from click<9,>=7.0->mlflow-skinny==2.19.0->mlflow) (0.4.6)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.19.0->mlflow) (4.0.11)\n",
      "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\krebi\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (2024.8.30)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading wrapt-1.17.0-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\krebi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.19.0->mlflow) (5.0.1)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading mlflow-2.19.0-py3-none-any.whl (27.4 MB)\n",
      "   ---------------------------------------- 0.0/27.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.8/27.4 MB 11.7 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 7.3/27.4 MB 20.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 12.8/27.4 MB 23.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 17.3/27.4 MB 23.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 22.0/27.4 MB 22.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.2/27.4 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 27.4/27.4 MB 21.1 MB/s eta 0:00:00\n",
      "Downloading mlflow_skinny-2.19.0-py3-none-any.whl (5.9 MB)\n",
      "   ---------------------------------------- 0.0/5.9 MB ? eta -:--:--\n",
      "   ---------------------------------------  5.8/5.9 MB 29.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.9/5.9 MB 25.3 MB/s eta 0:00:00\n",
      "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 12.7 MB/s eta 0:00:00\n",
      "Downloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "Downloading cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading databricks_sdk-0.40.0-py3-none-any.whl (629 kB)\n",
      "   ---------------------------------------- 0.0/629.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 629.7/629.7 kB 21.0 MB/s eta 0:00:00\n",
      "Downloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_api-1.29.0-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl (166 kB)\n",
      "Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
      "Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Downloading google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading wrapt-1.17.0-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: zipp, wrapt, Werkzeug, waitress, sqlparse, sqlalchemy, pyasn1, markdown, Mako, itsdangerous, graphql-core, cloudpickle, rsa, pyasn1-modules, importlib_metadata, graphql-relay, Flask, docker, deprecated, alembic, opentelemetry-api, graphene, google-auth, opentelemetry-semantic-conventions, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Flask-3.1.0 Mako-1.3.8 Werkzeug-3.1.3 alembic-1.14.0 cloudpickle-3.1.0 databricks-sdk-0.40.0 deprecated-1.2.15 docker-7.1.0 google-auth-2.37.0 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 importlib_metadata-8.5.0 itsdangerous-2.2.0 markdown-3.7 mlflow-2.19.0 mlflow-skinny-2.19.0 opentelemetry-api-1.29.0 opentelemetry-sdk-1.29.0 opentelemetry-semantic-conventions-0.50b0 pyasn1-0.6.1 pyasn1-modules-0.4.1 rsa-4.9 sqlalchemy-2.0.36 sqlparse-0.5.3 waitress-3.0.2 wrapt-1.17.0 zipp-3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock=pd.read_csv(r\"C:\\Users\\krebi\\OneDrive\\Desktop\\stock predict\\faang\\stock_data_mlflow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/30 15:39:51 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run fortunate-bear-754 at: http://127.0.0.1:5000/#/experiments/0/runs/b0640113c35b40dd8882aa870ca16900\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Run with UUID b0640113c35b40dd8882aa870ca16900 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test, y_pred))\n\u001b[0;32m     45\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_test, y_pred)\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     47\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m, mae)\n\u001b[0;32m     48\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m, rmse)\n",
      "File \u001b[1;32mc:\\Users\\krebi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:351\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[0m\n\u001b[0;32m    349\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(active_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    352\u001b[0m         (\n\u001b[0;32m    353\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is already active. To start a new run, first end the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    354\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun, call start_run with nested=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(active_run_stack[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[0;32m    357\u001b[0m     )\n\u001b[0;32m    358\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[1;31mException\u001b[0m: Run with UUID b0640113c35b40dd8882aa870ca16900 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "\n",
    "# Load Dataset\n",
    "\n",
    "\n",
    "# Feature Selection\n",
    "features = [\n",
    "    'Open', 'High', 'Low', 'Adj Close', 'Volume', 'Year',\n",
    "    'Company_Amazon', 'Company_Apple', 'Company_Facebook', 'Company_Google', 'Company_Netflix'\n",
    "]\n",
    "target = 'Close'\n",
    "\n",
    "X = stock[features]\n",
    "y = stock[target]\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Start MLflow Run\n",
    "with mlflow.start_run():\n",
    "    # Log Parameters\n",
    "    mlflow.log_param(\"model\", \"Linear Regression\")\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    \n",
    "    # Model Training\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "    # Evaluation Metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"R2 Score\", r2)\n",
    "\n",
    "    \n",
    "    # Infer Model Signature\n",
    "    signature = infer_signature(X_train, y_train)\n",
    "\n",
    "    # Log Model with Signature and Example\n",
    "    mlflow.sklearn.log_model(model, \"linear_regression_model\", signature=signature, input_example=X_train.iloc[0].to_dict())\n",
    "\n",
    "    # # Save Company Encoding Mapping\n",
    "    # company_mapping = {\n",
    "    #     'Amazon': 'Company_Amazon',\n",
    "    #     'Apple': 'Company_Apple',\n",
    "    #     'Facebook': 'Company_Facebook',\n",
    "    #     'Google': 'Company_Google',\n",
    "    #     'Netflix': 'Company_Netflix'\n",
    "    # }\n",
    "    # with open('company_mapping.pkl', 'wb') as f:\n",
    "    #     pickle.dump(company_mapping, f)\n",
    "    \n",
    "    print(f\"Model Trained. MAE: {mae}, RMSE: {rmse}, R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "features = [\n",
    "    'Open', 'High', 'Low', 'Volume',\n",
    "    'Company_Amazon', 'Company_Apple', 'Company_Facebook', 'Company_Google', 'Company_Netflix'\n",
    "]\n",
    "target = 'Close'\n",
    "\n",
    "X = stock[features]\n",
    "y = stock[target]\n",
    "X_log_transformed = X.apply(np.log1p)  # Features\n",
    "y_log_transformed = np.log1p(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log_transformed, y_log_transformed, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23055 entries, 0 to 23054\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Company           23055 non-null  object \n",
      " 1   Open              23055 non-null  float64\n",
      " 2   High              23055 non-null  float64\n",
      " 3   Low               23055 non-null  float64\n",
      " 4   Close             23055 non-null  float64\n",
      " 5   Adj Close         23055 non-null  float64\n",
      " 6   Volume            23055 non-null  int64  \n",
      " 7   Year              23055 non-null  int64  \n",
      " 8   Month             23055 non-null  int64  \n",
      " 9   Day               23055 non-null  int64  \n",
      " 10  Day_of_Week       23055 non-null  int64  \n",
      " 11  Company_Amazon    23055 non-null  int64  \n",
      " 12  Company_Apple     23055 non-null  int64  \n",
      " 13  Company_Facebook  23055 non-null  int64  \n",
      " 14  Company_Google    23055 non-null  int64  \n",
      " 15  Company_Netflix   23055 non-null  int64  \n",
      "dtypes: float64(5), int64(10), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "stock.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "X_log_transformed = X.apply(np.log1p)  # Features\n",
    "y_log_transformed = np.log1p(y)\n",
    "\n",
    "# Save the fitted scaler to a file\n",
    "with open(\"log_transformed_scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X_log_transformed, y_log_transformed), f)\n",
    "\n",
    "print(\"Scaler saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/30 16:09:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run linear_regression_model at: http://127.0.0.1:5000/#/experiments/0/runs/52527dcfbe194a6984e5dee42c467e15\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Ensure no active runs\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run(run_name=\"linear_regression_model\"):\n",
    "        # Log Parameters\n",
    "        mlflow.log_param(\"model\", \"Linear Regression\")\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "        # Model Training\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluation Metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Log Metrics\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"R2 Score\", r2)\n",
    "\n",
    "        # Model Signature\n",
    "        \n",
    "\n",
    "        # Log Model\n",
    "        mlflow.sklearn.log_model(\n",
    "            model, \n",
    "            \"linear_regression_model\", \n",
    "            \n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    mlflow.end_run(status=\"FAILED\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the run ends even if an error occurs\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation R2 Scores: [0.99993585 0.99992508 0.99993305 0.99992743 0.99993018]\n",
      "Mean Cross-Validation R2 Score: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/30 16:11:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run DecisionTree_regression_model at: http://127.0.0.1:5000/#/experiments/0/runs/63d216ceaef344c4a2d425d6427d088e\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import mlflow\n",
    "\n",
    "# Ensure no active runs\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run(run_name=\"DecisionTree_regression_model\"):\n",
    "        # Log Parameters\n",
    "        mlflow.log_param(\"model\", \"Decision Tree Regression\")\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "        # Model Training\n",
    "        model = DecisionTreeRegressor(random_state=42)\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='r2')\n",
    "        print(f'Cross-Validation R2 Scores: {scores}')\n",
    "        print(f'Mean Cross-Validation R2 Score: {np.mean(scores):.2f}')\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluation Metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Log Metrics\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"R2 Score\", r2)\n",
    "\n",
    "        \n",
    "\n",
    "        # Log Model\n",
    "        mlflow.sklearn.log_model(\n",
    "            model, \n",
    "            \"DecisionTree_regression_model\"\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    mlflow.end_run(status=\"FAILED\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the run ends even if an error occurs\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/30 16:14:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run RandomForest_regression_model at: http://127.0.0.1:5000/#/experiments/0/runs/f9afcd469e9742db80b57a601c60aa7d\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Ensure no active runs\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run(run_name=\"RandomForest_regression_model\"):\n",
    "        # Log Parameters\n",
    "        mlflow.log_param(\"model\", \"Random Forest Regression\")\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "        \n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "        param_grid = {\n",
    "            'n_estimators': [50,100],\n",
    "            'max_depth': [None, 10, ],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from GridSearch\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f'Best Parameters: {grid_search.best_params_}')\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Evaluation Metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Log Metrics\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"R2 Score\", r2)\n",
    "\n",
    "        \n",
    "\n",
    "        # Log Model\n",
    "        mlflow.sklearn.log_model(\n",
    "            model, \n",
    "            \"RandomForest_regression_model\"\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    mlflow.end_run(status=\"FAILED\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the run ends even if an error occurs\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost Regression Model\n",
      "🏃 View run XGBoost_regression_model at: http://127.0.0.1:5000/#/experiments/0/runs/dc6c274ab09c4de589f6ddf0bb69a9cd\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n",
      "Error: 'super' object has no attribute '__sklearn_tags__'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krebi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The XGBRegressor or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Ensure no active runs\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Set Experiment Name\n",
    "\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run(run_name=\"XGBoost_regression_model\"):\n",
    "        print(\"Training XGBoost Regression Model\")\n",
    "\n",
    "        # Log Parameters\n",
    "        mlflow.log_param(\"model\", \"XGBoost Regression\")\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "        # Initialize Model and GridSearchCV\n",
    "        model = XGBRegressor(random_state=42)\n",
    "        param_grid = {\n",
    "            'n_estimators': [10, 20],\n",
    "            'max_depth': [3, 5],\n",
    "            'learning_rate': [0.01, 0.1]\n",
    "        }\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=5,\n",
    "            scoring='r2',\n",
    "            n_jobs=-1,\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "        # Fit Model with GridSearch\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Best Parameters\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluation Metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Log Metrics\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"R2 Score\", r2)\n",
    "\n",
    "        # Log Model\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path=\"XGBoost_regression_model\"\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    mlflow.end_run(status=\"FAILED\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the run ends even if an error occurs\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM Regression Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krebi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The LGBMRegressor or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 18444, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 3.634877\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/30 16:15:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run LightGBM_regression_model at: http://127.0.0.1:5000/#/experiments/0/runs/c568470a128d4a288f4a8761292e8b63\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Ensure no active runs\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Set Experiment Name\n",
    "\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run(run_name=\"LightGBM_regression_model\"):\n",
    "        print(\"Training LightGBM Regression Model\")\n",
    "\n",
    "        # Log Parameters\n",
    "        mlflow.log_param(\"model\", \"LightGBM Regression\")\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "        # Initialize Model and GridSearchCV\n",
    "        model = LGBMRegressor(random_state=42)\n",
    "        param_grid = {\n",
    "            'n_estimators': [10,20],\n",
    "            'max_depth': [-1, 10],\n",
    "            'learning_rate': [0.01, 0.1]\n",
    "        }\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=5,\n",
    "            scoring='r2',\n",
    "            n_jobs=-1,\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "        # Fit Model with GridSearch\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Best Parameters\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluation Metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Log Metrics\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"R2 Score\", r2)\n",
    "\n",
    "        # Log Model\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path=\"LightGBM_regression_model\"\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    mlflow.end_run(status=\"FAILED\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the run ends even if an error occurs\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost Regression Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/30 16:16:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGBoost_serial_regression_model at: http://127.0.0.1:5000/#/experiments/0/runs/b8eec6876c85419fbcfefa8588198256\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Ensure no active runs\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run(run_name=\"XGBoost_serial_regression_model\"):\n",
    "        print(\"Training XGBoost Regression Model\")\n",
    "\n",
    "        # Log Parameters\n",
    "        mlflow.log_param(\"model\", \"XGBoost Regression\")\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "        # Initialize Model and GridSearchCV\n",
    "        model = XGBRegressor(random_state=42)\n",
    "        param_grid = {\n",
    "            'n_estimators': [10, 20],\n",
    "            'max_depth': [3, 5],\n",
    "            'learning_rate': [0.01, 0.1]\n",
    "        }\n",
    "\n",
    "        # grid_search = GridSearchCV(\n",
    "        #     estimator=model,\n",
    "        #     param_grid=param_grid,\n",
    "        #     cv=5,\n",
    "        #     scoring='r2',\n",
    "        #     n_jobs=-1,\n",
    "        #     verbose=2\n",
    "        # )\n",
    "\n",
    "        # # Fit Model with GridSearch\n",
    "        # grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # # Best Parameters\n",
    "        # best_model = grid_search.best_estimator_\n",
    "        # print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "        # mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluation Metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Log Metrics\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"R2 Score\", r2)\n",
    "\n",
    "        # Log Model\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path=\"XGBoost_serial_regression_model\"\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    mlflow.end_run(status=\"FAILED\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the run ends even if an error occurs\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linear1']\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "# registered_models = client.list_registered_models()\n",
    "# print([model.name for model in registered_models])\n",
    "registered_models = client.search_registered_models()\n",
    "print([model.name for model in registered_models])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
